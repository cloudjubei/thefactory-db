{
  "id": "67749a79-fda3-4c2b-9c35-b644c761b895",
  "status": "-",
  "title": "Ongoing Improvements",
  "description": "Various ongoing improvements to the project",
  "features": [
    {
      "id": "8a94bd10-9838-4e6f-9b6c-1b2060d6de40",
      "status": "=",
      "title": "Aim for close to 100% test coverage",
      "description": "We need to make sure that the tests cover as close as 100% of the codebase.\nObviously, things like the ai service with getting results from the AI cannot be fully tested - but we can test for many ranges of responses by mocking the LLM responses appropriately. The same idea should be taken everywhere to try to achieve 100% coverage.\n\nOne important thing is to make sure that data that is entering and leaving endpoints is validated thoroughly to make sure that it matches the expected schema. This should be part of the code and the tests should validate it too (i.e. malformed objects being rejected).\n\nThere needs to be a relevant section in @README.md  explaining how vital testing is and to refer to @docs/TESTING.md for all guidance related to writing tests and the standard for them. For reference there is also the @docs/CODE_STANDARD.md  document that highlights the coding standard within the project.\n\nNEVER FIX CODE JUST SO TESTS PASS - THE PROJECT CODE NEEDS TO MAKE SENSE AND WORK SO THE FEATURES ARE SATISFIED. TESTS ALWAYS NEED TO POKE AT HOLES AND EDGES OF THE CODE.",
      "context": [],
      "createdAt": "2025-09-19T10:36:00.358Z",
      "updatedAt": "2025-09-22T22:55:16.613Z",
      "blockers": []
    },
    {
      "id": "656fa3b5-b86a-41f3-8312-3aa1ed774c6d",
      "status": "=",
      "title": "Code standard",
      "description": "The document @docs/CODE_STANDARD.md  highlights the overall architecture and coding standards maintained in this project.\nThere is a clear reference to it inside @README.md and @docs/FILE_ORGANISATION.md so that anyone creating new features or updating existing ones will go to it.\nIt should be as succinct as possible, but explaining the idea as well as possible.\n\nGo over all the code and make sure that it satisfies the standards.",
      "context": [],
      "createdAt": "2025-09-19T10:36:08.586Z",
      "updatedAt": "2025-09-22T22:55:15.264Z",
      "blockers": []
    },
    {
      "id": "03858e2a-b346-4a6c-b711-427a85401e8e",
      "status": "+",
      "title": "Hybrid Search needs improvements",
      "description": "Right now the search doesn't seem to be pick up file names for keyword search.\nWhen the query is passed in - for embedding/semantic search - it should process the whole query and let the embeddings score like they do now. But for keyword search, the query should be space separated - and each such keyword should be tested against the file contents and the file name. File name should score separately from contents - it should be weighed 50/50 (file name vs contents) for the final score for the overall keyword score.",
      "context": [],
      "createdAt": "2025-09-23T12:18:10.277Z",
      "updatedAt": "2025-09-23T12:32:09.157Z",
      "completedAt": "2025-09-23T12:32:09.157Z"
    },
    {
      "id": "a83e8f50-66a3-44f7-a01f-057de5bb0a00",
      "status": "+",
      "title": "The current tests are too basic",
      "description": "We need to have more advanced tests to really see that the search functionality is working appropriately.\nWe need two sets of files - 1 made up non-code documents and 2 this project's files (all of them).\n\nWe need to have the tests cover all sorts of cases for using the hybrid search - when the weight is 0, 0.2, 0.5, 0.8, 1.0 . When there is information just in the title of the file, just in the contents or just in the embeddings (semantically it's there).",
      "context": [],
      "createdAt": "2025-09-23T12:45:38.880Z",
      "updatedAt": "2025-09-23T12:51:52.069Z",
      "completedAt": "2025-09-23T12:51:52.069Z"
    },
    {
      "id": "f018a399-a2fb-47f5-9990-b89fc7381097",
      "status": "+",
      "title": "Need to create an e2e tests using a real db under `tests/e2e`",
      "description": "First we need to explain to the user how to easily spin up a test database with docker compose that will be used for e2e tests.\nThen assuming the database is running, there need to be e2e tests for indexing and most importantly for hybrid-search - mirroring all the tests inside `tests` that would require to call `openDatabase`",
      "context": [],
      "createdAt": "2025-09-23T13:02:45.316Z",
      "updatedAt": "2025-09-23T16:59:28.369Z",
      "blockers": [],
      "completedAt": "2025-09-23T16:17:21.497Z"
    },
    {
      "id": "bd58e850-de61-4e54-adba-9a7b49e76f29",
      "status": "+",
      "title": "Make more complex e2e tests",
      "description": "THere should be an equivalent e2e test version of @tests/hybrid-search-advanced.test.ts .\nWe should have one version for entities and one for documents.\nThe goal is to stress test different weights to the scores [0,0.2,0.5,0.8,1] of the keywords vs embedding weights.\nWe also make sure that files are picked up based on their file names - so there need to be appropriate tests for that.\nFollow @docs/TESTING.md for standards. \nMake sure the tests are as atomic and self-contained as possible.\nPrefer more easily failable tests rather than a huge battery of tests that could fail at the beginning.",
      "context": [
        "tests/hybrid-search-advanced.test.ts",
        "docs/TESTING.md"
      ],
      "createdAt": "2025-09-23T15:07:16.099Z",
      "updatedAt": "2025-09-23T17:00:30.567Z",
      "blockers": [],
      "completedAt": "2025-09-23T16:20:36.753Z"
    },
    {
      "id": "94a33d4a-7698-4962-86cd-cb3a19d7f664",
      "status": "+",
      "title": "Tests fail",
      "description": "",
      "context": [],
      "createdAt": "2025-09-23T17:00:26.541Z",
      "updatedAt": "2025-09-23T18:08:26.001Z",
      "blockers": [],
      "completedAt": "2025-09-23T17:11:58.623Z"
    },
    {
      "id": "734c141d-83b8-4a4c-8ed5-75ef2d5ea874",
      "status": "+",
      "title": "Title doesn't get taken into account when hybrid searching",
      "description": "Inside the definition of hybrid search in @src/utils.ts - for documents, `src` isn't taken into account - the name portion of it should be. But even better, we should enforce accepting a name, inside DocumentInput, and store it in the database and then keyword search (inside hybrid search) should also test itself against this value.",
      "context": [
        "src/utils.ts"
      ],
      "createdAt": "2025-09-23T17:01:25.209Z",
      "updatedAt": "2025-09-24T03:00:18.323Z",
      "blockers": [],
      "completedAt": "2025-09-24T03:00:18.323Z"
    },
    {
      "id": "4016b214-feaf-41a0-b56c-f61932f3250c",
      "status": "+",
      "title": "Complex e2e from this project's codebase",
      "description": "Following @tests/e2e/documents-hybrid-advanced.e2e.test.ts and @tests/hybrid-search-advanced.test.ts - there need to be advanced e2e tests using this project's code files as documents to search against, checking various weight settings.\nThese tests need to be exact - i.e. they should always return the same expected files in the correct order for the given weight.",
      "context": [
        "tests/e2e/documents-hybrid-advanced.e2e.test.ts",
        "tests/hybrid-search-advanced.test.ts"
      ],
      "blockers": [],
      "createdAt": "2025-09-23T18:11:34.201Z",
      "updatedAt": "2025-09-23T22:03:29.894Z",
      "completedAt": "2025-09-23T22:03:29.894Z"
    },
    {
      "id": "39e9a493-5433-405b-8fc0-89f4ec5d3e18",
      "status": "+",
      "title": "Augment the existing hybrid search tests",
      "description": "All the tests that use hybrid search (both e2e and normal) need to be updated to include cases where a list of keywords is presented.\\nA test case needs to show having matches at the start of the list, another in the middle, another at the end, another no matches, and yet another having a sentence that doesn't match in terms of keywords but semantically does.",
      "context": [],
      "blockers": [],
      "createdAt": "2025-09-23T22:08:33.087Z",
      "updatedAt": "2025-09-23T22:12:35.953Z",
      "completedAt": "2025-09-23T22:12:35.953Z"
    },
    {
      "id": "ad2a782a-d8f1-4560-83f5-2e972c9ed02f",
      "status": "+",
      "title": "Entities tests need to show that metadata isn't taken into account",
      "description": "The entities hybrid search tests - @tests/e2e/entities-hybrid-advanced.e2e.test.ts and @tests/e2e/entities-hybrid.e2e.test.ts need to be updated with tests that show that even if metadata holds relevant data - then it won't change a hybrid search result.",
      "context": [
        "tests/e2e/entities-hybrid-advanced.e2e.test.ts",
        "tests/e2e/entities-hybrid.e2e.test.ts"
      ],
      "blockers": [],
      "createdAt": "2025-09-23T22:23:59.756Z",
      "updatedAt": "2025-09-23T22:57:32.181Z",
      "completedAt": "2025-09-23T22:57:32.181Z"
    },
    {
      "id": "057eb355-399f-443b-b98d-6c2f46a953da",
      "status": "+",
      "title": "e2e tests suffer from randomness",
      "description": "It seems that a few of the e2e tests give different results on different runs. This seems to be caused by some randomness being involved at tokenization or even more probably at the embedding stage.\nWe should make sure that two items that are exactly the same - should get the same exact fts tokens and embeddings.\nThere shouldn't be randomisation at play.",
      "context": [],
      "blockers": [],
      "createdAt": "2025-09-23T22:57:35.778Z",
      "updatedAt": "2025-09-24T00:25:29.131Z",
      "completedAt": "2025-09-24T00:25:29.131Z"
    },
    {
      "id": "4c2bf377-ffe0-4ad3-8b2d-f3cc9ba32592",
      "status": "+",
      "title": "when multiple keywords are input they are not treated separately",
      "description": "I keep observing a textScore of 0 when calling `searchDocuments` in @src/index.ts . When only one keyword is input, the textScore is correct, but with multiple keywords that are space separated - the result is pretty much always 0.\nWhat should happen is that the input should be space separated, and for each such keyword the textScore should be computed and then the maximum of all these keywords should be taken - that should be the final score for a set of keywords. This should be directly inside the SQL `hybrid_search_entities` and `hybrid_search_documents` functions.",
      "context": [
        "src/index.ts"
      ],
      "blockers": [],
      "createdAt": "2025-09-24T02:37:08.544Z",
      "updatedAt": "2025-09-24T02:42:00.191Z",
      "completedAt": "2025-09-24T02:42:00.191Z"
    },
    {
      "id": "04391c02-652b-4dad-b59a-2eda2bccf1d3",
      "status": "-",
      "title": "Batching of embeddings",
      "description": "In @src/index.ts in the function `upsertDocuments` we are embedding the content of many documents at once and this takes a long time. So we require this improvement - the @src/utils/embeddings.ts needs to allow batched embeddings, so that it can quicker do the whole batch in one go. Sample code for the usage of this is commented out in `upsertDocuments` .",
      "context": [
        "src/index.ts",
        "src/utils/embeddings.ts"
      ],
      "blockers": [],
      "createdAt": "2025-09-29T20:28:01.709Z",
      "updatedAt": "2025-09-29T22:44:49.775Z",
      "rejection": "The latest addition of `embedBatchAsync` and using it in `upsertDocuments` causes a crash.\nThere need to be appropriate unit tests and e2e tests following how others are done in the `tests` folder that will test out this functionality once it's fixed."
    },
    {
      "id": "77101a35-86dd-42f7-b42b-5c30fedc7713",
      "status": "+",
      "title": "Check hashes before embeddings",
      "description": "In `upsertDocuments` in @src/index.ts before proceeding into the embeddings, there should be a function that would accept the src/ids of the documents and their contents and would return all the documents that would be updated (thus requiring embeddings) and then only these documents would be passed onto the embeddings and the actual upsert. The embeddings are the bottleneck, so we need to make sure that as few documents as possible get re-embedded - thus we need a pre-emptive hash check.",
      "context": [
        "src/index.ts"
      ],
      "blockers": [],
      "createdAt": "2025-09-29T22:45:51.048Z",
      "updatedAt": "2025-09-29T22:49:28.605Z",
      "completedAt": "2025-09-29T22:49:28.605Z"
    }
  ],
  "featureIdToDisplayIndex": {
    "656fa3b5-b86a-41f3-8312-3aa1ed774c6d": 1,
    "8a94bd10-9838-4e6f-9b6c-1b2060d6de40": 2,
    "03858e2a-b346-4a6c-b711-427a85401e8e": 3,
    "a83e8f50-66a3-44f7-a01f-057de5bb0a00": 4,
    "f018a399-a2fb-47f5-9990-b89fc7381097": 5,
    "bd58e850-de61-4e54-adba-9a7b49e76f29": 6,
    "94a33d4a-7698-4962-86cd-cb3a19d7f664": 7,
    "4016b214-feaf-41a0-b56c-f61932f3250c": 8,
    "39e9a493-5433-405b-8fc0-89f4ec5d3e18": 9,
    "ad2a782a-d8f1-4560-83f5-2e972c9ed02f": 10,
    "057eb355-399f-443b-b98d-6c2f46a953da": 11,
    "4c2bf377-ffe0-4ad3-8b2d-f3cc9ba32592": 12,
    "734c141d-83b8-4a4c-8ed5-75ef2d5ea874": 13,
    "77101a35-86dd-42f7-b42b-5c30fedc7713": 14,
    "04391c02-652b-4dad-b59a-2eda2bccf1d3": 15
  },
  "createdAt": "2025-09-19T01:04:36.087Z",
  "updatedAt": "2025-09-19T01:04:36.087Z"
}